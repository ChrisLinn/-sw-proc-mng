# Quality Assurance

_updated at: 2017-05-23-19-09_

+ ~~Quality Assurance~~
    + ~~to achieve quality standards~~
        * ~~quality standards~~
            - ~~one of the constraints~~
                + ~~other constraints~~
                    * ~~budget~~
                    * ~~resource~~
                    * ~~product~~
                    * ~~organizational~~


## Quality
+ ~~is an attribute (that can be broken into some attributes) and is measurable~~
+ cannot post-hoc / after building the system
+ need to be Built into the Design (at the beginning)
+ ~~Measuring quality gives~~
+ ~~quality of design~~
    * ~~quality of conformance~~
+ the quality of the process influences the quality of the product
    * If a software engineer cannot directly monitor the quality attributes of the product
        * then they will often instead monitor the quality attributes of the processes used
+ Perspective on quality
    * The end user perspective - ultimately matters
        - external quality characteristics
            + fit for purpose
            + reliable
            + reasonable performance
            + easy to learn and use
            + help user in achieving their goal
    * The developer’s perspective -  increases the likelihood to satisfy the end user
        - internal quality characteristics - easy to understand and maintain for developers and maintainers, so that less likely to make mistakes, and can focus on increasing quality with respect to the end user
            + num of faults
            + ease of modifying the system
            + ease of testing the system
            + the ease of understanding the system design
            + the re-usability of components
            + conformance to requirements
            + resource usage
            + performance
- quality dependent on the perspective, interpretation, and expectations of individuals
    +  difﬁcult to measure or assess directly
        *  wanna remove bias and be more objective
            - use quality models
                + to decompose quality into a number of attributes which can be measured or evaluated more objectively
        
### Quality models
+ a relatively abstract characterisation of quality
    * Meets explicit functional & non-functional req’s
        - correct, complete, consistent
    * Adhere internal & external standards
    * Meets implicit quality req’s
        - req's for performance - reliable, usable, extendable ...
+ ~~example~~
    * ~~McCall’s quality model~~
    * ~~ISO9126~~

### SW quality dilemma
+ which process and activities are worthwhile to apply in order to achieve software quality
    * why ask
        - quality assurance has a cost
            + ~~salary~~
            + ~~software licenses~~
            + ~~hardware~~
            + ~~time~~
        - lack of quality also has a cost
            + ~~user to deal with low quality~~
            + ~~supplier to knock-on~~
                * ~~potential users don't choose~~
                * ~~current user don't upgrade~~
            + ~~supplier to maintain~~
                * ~~faults more common~~
                * ~~hard to make changes~~
                    - ~~correcting fault~~
                    - ~~adding new features~~
                    - ~~re-factoring~~
    + answer
        * good enough (e.g. more-used more reliable / no known faults)
            - need to estimate
                + cost of the quality assurance activities
                + cost of the possible risks

### The cost of quality
+ too costly?
    * ~~e.g.~~
        + ~~no formal team reviews, ask user instead for feedback and correct faults~~
        + ~~release the system and correct errors as users find/report them~~
    * Studies indicate that
        * later a fault is detected (in SDLC)
            * more costly to locate and repair


## Quality & Process
+ how to change if proj often lacking 1 or more quality attributes
    * ~~hire better developers?~~
        * ~~there aren't many~~
    + change the processes (change how to build the proj)
- The quality of the product depends on the quality of the process.
    + the process can be defined, managed, measured, and __improved__
        * Improve quality through improving quality attributes 
            - ~~means employing a more suitable process~~
- to achieve quality
    + must be practical
        * decide which quality attributes are the most important
            - so
                + more effort and resources
            - but
                + do not neglect the others
            * must
                * Decide upon targets for process measures
                    - ~~e.g. acceptable defect rates from inspections of code or inspections of designs~~
                * Decide upon targets for product measures
                    - ~~e.g. the target reliability or performance estimates for you system~~
        + if targets not met
            * reduce your targets
            * or change the processes (preferably)
        + ~~not simply because the standard requires it but understand why needed and make sure that they ﬁts with the goal~~
+ Improving quality via process improvement
    * improve the quality of our processes
        - Capability Maturity Model (CMM)
            + aims to provide an assessment of the Process Maturity Model
                * ~~how well the processes are defined~~
                * ~~how well the processes are understood~~
                * ~~how well the processes are applied~~
            + ~~rating~~
                * ~~Initial~~
                * ~~Repeatable~~
                * ~~Defined~~
                * ~~Managed (measure and predict)~~
                * ~~Optimised~~

## ~~Quality Mngment~~
+ ~~Checks project deliverables~~
+ ~~Manage release testing process~~
+ ~~![Quality management process](pics/quality-management-process.png)~~
+ ~~Quality Plan~~
    * ~~Product introduction~~
    * ~~Product plans~~
    * ~~Process descriptions~~
    * ~~Quality goals~~
    * ~~Risks and risk Management~~
    * ~~Quality Assurance~~


## Quality Assurance
+ __monitoring and evaluation__ of the various aspects of a project, service, or facility to ensure that __standards__ of quality are being met.
+ != guarantee
    * ~~only to provide a high level of assurance, or a high degree of confidence~~
        - ~~that the program meets the needs~~
+ != quality control
    * quality assurance
        - to improve quality during development
    * quality control
        * testing a product before its release
        - to decide whether to release
+ ~~ability to exert control over the level of assurance~~
    * ~~important~~
    * ~~distinguishes engineering from ad-hoc development~~
    * ~~need to understand the quality attributes~~
    * ~~have methods to build these attributes~~
+ main methods for assuring quality 
    * Testing and Measurement
        - ~~dynamic execution of a system to~~
            - ~~finding faults (testing functional requirements)~~
            - ~~measuring whether the system meets its non-function requirements~~
    * Audits
        - reviews of processes and teams to
            + determine if a particular product or process conforms to standards
        - assesses whether a given artifact complies with a specified standard or process
            + does not aim to find defects in logic or meaning of an artifact
        - difference from a peer review or technical review
            + authors not involved at all
            + performed by an external team
        - types
            + product audits
                * assesses whether a product complies with a standard
            + process audits
                * assesses whether a team is following speciﬁed processes
        + more objective than technical reviews
            * a team is following a process or not
                - ~~lack of evidence can be a sign~~
    * Technical reviews
        - reviews of artifacts performed by __peers__ to
            + uncover problems/defects in an artifact
            + determine the quality of an artifact
                + e.g stable
            + and seek ways to improve the artifact
        - soft
            + nothing is executed
        - but useful
            + Reviews can be performed on any software artifacts
                * hard ones (e.g testing & measurement) can be performed only on executable artifacts
            + Early reviews saves costs, can find faults before testing & measurement
            + programmers make more mistakes when correcting faults found during testing than review
                * ~~due to internal pressure of getting software released~~
            + Review fault detection rate is high
            + Reviews find the actual faults in source code
                + testing merely indicates "somewhere" and needs locating the fault
        * a type of __peer review__
            - userful
                + different assumptions & understanding
                + people rarely find their own faults and problems
            - ~~but authors most deﬁnitely should review their artifacts before passing them on for peer review.~~
* peer reviews
    + Informal reviews
        + technical review is informal according to W11L2 slides
        * Simple Desk Check /casual meeting with a colleague
            * look over sth and provide feedback
        * Aims to improve quality of a document
        * no formal guidelines or procedures
        * Less effective than formal reviews
            - lack of
                + diversity found in a group
                + focus by the reviewer
            * Checklists can help to improve the effectiveness
                - ~~a list of generic questions about an artifact~~
                - ~~a generic checklist for requirements specifications~~
    + Formal reviews
        * a meeting of a group of project stakeholders
            - such as developers, project managers, and clients
            - leverage from the diversity of the individuals within the group
            - more productive than having several individuals
                + ~~people like to show off how smart they are~~
        * for the purpose of improving the quality of a software artifact
            - such as a requirement speciﬁcation, or a piece of code
        * Improving artifact quality by
            - uncovering logical errors within the artifact
            - verifying that the artifact meets its specification
            - ensuring that the artifact achieves the requirements set out by some speciﬁed standards
        * Review meetings
            - constraints
                + Small – 3-5 people
                    * ~~too much comm, too many opinions~~
                + Not more than 90 minutes
                    * ~~can focus for a long time~~
                    * ~~review only a part of the an artifact if it is too large to review in 90 minutes~~
                + roles should be filled
                    * types
                        - Review leader
                            + ~~organising~~
                                * ~~finding reviewers~~
                                * ~~organising time/place~~
                                * ~~distributing checklists~~
                                * ~~distributing the artifact along with any supporting documentation~~
                                    * ~~e.g. a speciﬁcation of the artifact~~
                        - Author
                        - Reviewer
                        - Recorder
                    + ~~rules~~
                        + ~~one person can fulfil more than one role except author~~
                        + ~~if fulfilling two roles, one should be the role of reviewer~~
            + procedure
                * Start with an introduction of the artifact from author
                * Author ‘walks through’ the artifact in a logical manner, explains the content
                * Reviewers raise ‘issues’
                    - many of the issues are raised by the author themselves
                        + stepping through in a logical manner and explaining forces to think in a new way 
                * Recorded takes note of any issues identified by the team
                * After the walk through
                    - review team make one recommendation
                        + accept the artifact without further changes
                        + or accept the artifact with minor changes
                        + or reject the artifact, requesting non-trivial changes, another review later when changes made
                * After the meeting
                    - recorder produces a report on the ﬁnding of the review
                        + list of issues
                    - author(s) make the changes and typically produce a response document
                        + outlining where and how changed
                        + facilitates subsequent reviews
                    - Submit report and response as part of the project records
            + Walkthrough vs inspections
                * Both technical
                * similar
                    * rely on groups ~~to improve the quality of an artifact~~
                    * consist of the group walking through ~~an artifact to ﬁnd problems~~
                * Differences
                    - Moderator (walkthrough leader) roles 
                        + an author in walkthrough
                        + a reviewer in inspection
                    - Reviewers Preparation 
                        + no in walkthrough
                        + inspect the artifact and take notes into the meeting in inspection
                    - Taking action
                        + possible solutions may be discussed in walkthrough
                        + defects and inconsistencies should be identified, but not corrected in inspection
            + Review tips
                * Use constructive criticism
                    - ~~to ask questions so that the author can ﬁnd the issues themselves, rather than point them out directly~~
                * Stick to the agenda
                * Minimise discussion
                    * ~~on whether the raised issue is a problem~~
                * Allocate time for reviews
            + Review metrics
                * Error density = Err / S
                    - Err: total number of errors
                    - S: the size of an artifact
                        + e.g. num of pages/models
                    - why used
                        + review only a portion of each artifact
                            * must be representative
                            * must be large enough
                        + calculate the error density of each artifact using the results of the review
                        + Teams can decide which artifacts are error-prone and focus on them, should spend more time reviewing them
                * Rate of error detection = Err / Effort
                    - Effort: the total effort
                        + preparation, reviewing, and reworking
                * usage
                    - planning and prediction
                    * the effectiveness of reviews
                        - Study shows cost effectiveness of reviews 
                            + bigger costs during testing
                        - ~~not possible to measure directly after the review~~
                            - ~~must wait until at least after further quality metrics have been collected, such as testing data~~
                    + offer way to assess the value of reviewing an artifact before it is actually reviewed
                        * ~~tight deadlines~~
                        * ~~not possible to review all rigorously~~
                        * ~~sample-driven reviews~~